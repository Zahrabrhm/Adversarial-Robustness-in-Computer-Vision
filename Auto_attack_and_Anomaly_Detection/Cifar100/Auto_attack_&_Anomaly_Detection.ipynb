{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5bJB-CIYD3xE"
   },
   "source": [
    "Before starting we need to import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MjoLUW9aCofP"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import argparse\n",
    "import sys\n",
    "sys.argv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YAvCsdRbCdJQ"
   },
   "source": [
    "To ensure we get reproducible results we set the random seed for Python, Numpy and PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BN4WxssWDLJN"
   },
   "outputs": [],
   "source": [
    "SEED=1234\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic=True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='PyTorch CIFAR 10 Training')\n",
    "parser.add_argument('--batch-size', type=int, default=128, metavar='N',\n",
    "                    help='input batch size for training (default: 128)')\n",
    "parser.add_argument('--test-batch-size', type=int, default=128, metavar='N',\n",
    "                    help='input batch size for testing (default: 128)')\n",
    "parser.add_argument('--epochs', type=int, default=76, metavar='N',\n",
    "                    help='number of epochs to train')\n",
    "parser.add_argument('--weight-decay', '--wd', default=2e-4,\n",
    "                    type=float, metavar='W')\n",
    "parser.add_argument('--lr', type=float, default=0.1, metavar='LR',\n",
    "                    help='learning rate')\n",
    "parser.add_argument('--momentum', type=float, default=0.9, metavar='M',\n",
    "                    help='SGD momentum')\n",
    "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                    help='disables CUDA training')\n",
    "parser.add_argument('--epsilon', default=0.031,\n",
    "                    help='perturbation')\n",
    "parser.add_argument('--num-steps', default=10,\n",
    "                    help='perturb number of steps')\n",
    "parser.add_argument('--step-size', default=0.007,\n",
    "                    help='perturb step size')\n",
    "parser.add_argument('--beta', default=6.0,\n",
    "                    help='regularization, i.e., 1/lambda in TRADES')\n",
    "parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                    help='random seed (default: 1)')\n",
    "parser.add_argument('--log-interval', type=int, default=100, metavar='N',\n",
    "                    help='how many batches to wait before logging training status')\n",
    "parser.add_argument('--model-dir', default='./model-cifar-wideResNet',\n",
    "                    help='directory of model for saving checkpoint')\n",
    "parser.add_argument('--save-freq', '-s', default=1, type=int, metavar='N',\n",
    "                    help='save frequency')\n",
    "\n",
    "args, unknown = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion * planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion * planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion * planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion * planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion * planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion * planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=100):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "def test():\n",
    "    net = ResNet18()\n",
    "    y = net(torch.randn(1, 3, 32, 32))\n",
    "    print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "torch.manual_seed(args.seed)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7QPDKtcWSPop"
   },
   "source": [
    "1.  first we need to load the last checkpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "im4jWiRDO0hM",
    "outputId": "f259735c-c0c3-408f-b871-0a16a41a9727"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=512, out_features=100, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = ResNet18()\n",
    "net.load_state_dict(torch.load('/content/model-cifar-wideResNet/model-resnet-epoch76.pt'))\n",
    "net.to(device) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "itKdNAobN8IF"
   },
   "source": [
    "2.  Applying Auto attack to dataset and evaluate our trained model:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9U2cAD5ZOVaN"
   },
   "source": [
    "*  in order to apply auto attack, we need to get all of required packages from Auto Attack github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n0CWCTzOObqk",
    "outputId": "3255b2c4-34fb-4b77-f1d9-2167f528d196"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting git+https://github.com/fra31/auto-attack\n",
      "  Cloning https://github.com/fra31/auto-attack to /tmp/pip-req-build-kv9_pevp\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/fra31/auto-attack /tmp/pip-req-build-kv9_pevp\n",
      "  Resolved https://github.com/fra31/auto-attack to commit a39220048b3c9f2cca9a4d3a54604793c68eca7e\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Building wheels for collected packages: autoattack\n",
      "  Building wheel for autoattack (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for autoattack: filename=autoattack-0.1-py3-none-any.whl size=36249 sha256=ebfb8b3f1ef60b8f4b161db45e32f6f658b78464440e5621fb397865d11e36f0\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-v7gt6m0p/wheels/e5/00/6a/fb12d1eaa81d79f8c0585bdddc361ca48c9633e9549db68aef\n",
      "Successfully built autoattack\n",
      "Installing collected packages: autoattack\n",
      "Successfully installed autoattack-0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/fra31/auto-attack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WPbv5NCTQfFd"
   },
   "source": [
    "*  Applying AA attack for Linf setting and calculating Adversarial attack rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9F9ygv57c1OF",
    "outputId": "36567e0a-f246-48f4-e400-58da591f2f21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting parameters for standard version\n"
     ]
    }
   ],
   "source": [
    "from autoattack import AutoAttack\n",
    "adversary = AutoAttack(net, norm='Linf', eps=0.031, version='standard')\n",
    "adversary = AutoAttack(net, norm='Linf', eps=0.031, version='standard')\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "l = [x for (x, y) in test_loader]\n",
    "x_test = torch.cat(l, 0)\n",
    "l = [y for (x, y) in test_loader]\n",
    "y_test = torch.cat(l, 0)\n",
    "adv_complete = adversary.run_standard_evaluation(x_test, y_test,bs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "37s13pZw5BeI",
    "outputId": "da0e2abd-bd7b-4422-e7af-4a9d4b3b2011"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarial attack rate: 90.27%\n"
     ]
    }
   ],
   "source": [
    "adv_loader_Linf = torch.utils.data.DataLoader(adv_complete, batch_size=100, shuffle=False, num_workers=2)\n",
    "num_total_images = 0\n",
    "num_successful_attacks = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "    for adv_images in adv_loader_Linf:\n",
    "        adv_images = adv_images.to(device)\n",
    "        outputs_adv = net(adv_images)\n",
    "        _, predicted_adv = torch.max(outputs_adv.data, 1)\n",
    "\n",
    "        # Count the number of adversarial examples that were successfully attacked\n",
    "        for i in range(len(images)):\n",
    "            if predicted[i] != predicted_adv[i]:\n",
    "                num_successful_attacks += 1\n",
    "        \n",
    "        # Increment the total number of images\n",
    "        num_total_images += len(images)\n",
    "\n",
    "# Calculate the adversarial attack rate\n",
    "attack_rate = (num_successful_attacks / num_total_images) * 100\n",
    "print(f\"Adversarial attack rate for Linf norm: {attack_rate:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "idDPPMhGaJeN"
   },
   "source": [
    "*  Applying AA attack for Linf setting and calculating Adversarial attack rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lyyvRSsiaIm_"
   },
   "outputs": [],
   "source": [
    "from autoattack import AutoAttack\n",
    "adversary = AutoAttack(net, norm='L2', eps=0.031, version='standard')\n",
    "l = [x for (x, y) in test_loader]\n",
    "x_test = torch.cat(l, 0)\n",
    "l = [y for (x, y) in test_loader]\n",
    "y_test = torch.cat(l, 0)\n",
    "adv_complete_L2 = adversary.run_standard_evaluation(x_test, y_test,bs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_pQTNH8paLzn"
   },
   "outputs": [],
   "source": [
    "adv_loader_L2 = torch.utils.data.DataLoader(adv_complete_L2, batch_size=100, shuffle=False, num_workers=2)\n",
    "num_total_images = 0\n",
    "num_successful_attacks = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "    for adv_images in adv_loader_L2:\n",
    "        adv_images = adv_images.to(device)\n",
    "        outputs_adv = net(adv_images)\n",
    "        _, predicted_adv = torch.max(outputs_adv.data, 1)\n",
    "\n",
    "        # Count the number of adversarial examples that were successfully attacked\n",
    "        for i in range(len(images)):\n",
    "            if predicted[i] != predicted_adv[i]:\n",
    "                num_successful_attacks += 1\n",
    "        \n",
    "        # Increment the total number of images\n",
    "        num_total_images += len(images)\n",
    "\n",
    "# Calculate the adversarial attack rate\n",
    "attack_rate = (num_successful_attacks / num_total_images) * 100\n",
    "print(f\"Adversarial attack rate for L2 norm: {attack_rate:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UGGepO7OMQJR"
   },
   "source": [
    "3.  Anomaly detection:\n",
    "\n",
    "*  to apply our anomally detection algorithm we download the packages from github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Yc5P5vuMRvD",
    "outputId": "8b5aa8ed-2552-45ca-d665-f33377e80cf8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Mean-Shifted-Anomaly-Detection'...\n",
      "remote: Enumerating objects: 55, done.\u001b[K\n",
      "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
      "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
      "remote: Total 55 (delta 4), reused 4 (delta 3), pack-reused 46\u001b[K\n",
      "Unpacking objects: 100% (55/55), 17.41 KiB | 1.24 MiB/s, done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/talreiss/Mean-Shifted-Anomaly-Detection.git\n",
    "%cd Mean-Shifted-Anomaly-Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wbGqGhrRXnla",
    "outputId": "6df8a207-0850-4168-91b0-a17f3921216d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# Download and load the CIFAR-100 dataset\n",
    "cifar100_dataset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "# Create empty lists to hold datasets for each class\n",
    "class_datasets = [[] for i in range(100)]\n",
    "\n",
    "# Loop over the entire dataset and add each image to its respective class dataset\n",
    "for i in range(len(cifar100_dataset)):\n",
    "    image, label = cifar100_dataset[i]\n",
    "    class_datasets[label].append((image, label))\n",
    "\n",
    "# Create separate data loaders for each class dataset\n",
    "class_loaders = []\n",
    "batch_size = 64\n",
    "shuffle = True\n",
    "for i in range(100):\n",
    "    class_loader = torch.utils.data.DataLoader(class_datasets[i], batch_size=batch_size, shuffle=shuffle)\n",
    "    class_loaders.append(class_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sEWfEOqmXvH-",
    "outputId": "c16abae1-9452-4cbb-bb5a-85edb4de029b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting git+https://github.com/fra31/auto-attack\n",
      "  Cloning https://github.com/fra31/auto-attack to /tmp/pip-req-build-p01w189o\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/fra31/auto-attack /tmp/pip-req-build-p01w189o\n",
      "  Resolved https://github.com/fra31/auto-attack to commit a39220048b3c9f2cca9a4d3a54604793c68eca7e\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "setting parameters for standard version\n",
      "using standard version including apgd-ce, apgd-t, fab-t, square.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "PYDEV DEBUGGER WARNING:\n",
      "sys.settrace() should not be used when the debugger is being used.\n",
      "This may cause the debugger to stop working correctly.\n",
      "If this is needed, please check: \n",
      "http://pydev.blogspot.com/2007/06/why-cant-pydev-debugger-work-with.html\n",
      "to see how to restore the debug tracing back correctly.\n",
      "Call Location:\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/autoattack/checks.py\", line 100, in check_dynamic\n",
      "    sys.settrace(tracefunc)\n",
      "\n",
      "\n",
      "PYDEV DEBUGGER WARNING:\n",
      "sys.settrace() should not be used when the debugger is being used.\n",
      "This may cause the debugger to stop working correctly.\n",
      "If this is needed, please check: \n",
      "http://pydev.blogspot.com/2007/06/why-cant-pydev-debugger-work-with.html\n",
      "to see how to restore the debug tracing back correctly.\n",
      "Call Location:\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/autoattack/checks.py\", line 102, in check_dynamic\n",
      "    sys.settrace(None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial accuracy: 1.00%\n",
      "apgd-ce - 1/1 - 5 out of 5 successfully perturbed\n",
      "robust accuracy after APGD-CE: 0.00% (total time 0.1 s)\n",
      "max Linf perturbation: 0.00000, nan in tensor: 0, max: 1.00000, min: 0.00000\n",
      "robust accuracy: 0.00%\n"
     ]
    }
   ],
   "source": [
    "class AdversarialDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        return sample, label\n",
    "\n",
    "l = [x for (x, y) in class_loaders[0]]\n",
    "x_test = torch.cat(l, 0)\n",
    "l = [y for (x, y) in class_loaders[0]]\n",
    "y_test = torch.cat(l, 0)\n",
    "\n",
    "!pip install git+https://github.com/fra31/auto-attack\n",
    "from autoattack import AutoAttack\n",
    "adversary_Linf = AutoAttack(net, norm='Linf', eps=0.031, version='standard')\n",
    "adv_complete_Linf = adversary_Linf.run_standard_evaluation(x_test, y_test,bs=64)   \n",
    "\n",
    "adv_dataset_Linf = AdversarialDataset(adv_complete_Linf, y_test)\n",
    "adv_loader_Linf = torch.utils.data.DataLoader(adv_dataset_Linf, batch_size=100, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aIUAtiszXx28",
    "outputId": "954b59d8-e4eb-4020-cbf7-114edc139855"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, images, labels):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image = self.images[index]\n",
    "        label = self.labels[index]\n",
    "        return torch.from_numpy(image), torch.tensor(label)\n",
    "\n",
    "# Load datasets\n",
    "dataset1 = x_test\n",
    "dataset2 = adv_complete_Linf\n",
    "\n",
    "# Create labels\n",
    "labels1 = np.ones(dataset1.shape[0])\n",
    "labels2 = np.zeros(dataset2.shape[0])\n",
    "\n",
    "# Concatenate datasets\n",
    "concatenated_dataset = np.concatenate((dataset1, dataset2), axis=0)\n",
    "concatenated_labels = np.concatenate((labels1, labels2), axis=0)\n",
    "\n",
    "# Shuffle dataset\n",
    "permutation = np.random.permutation(concatenated_dataset.shape[0])\n",
    "concatenated_dataset = concatenated_dataset[permutation]\n",
    "concatenated_labels = concatenated_labels[permutation]\n",
    "\n",
    "# Create dataset and dataloader\n",
    "custom_dataset = CustomDataset(concatenated_dataset, concatenated_labels)\n",
    "batch_size = 32\n",
    "num_workers = 4\n",
    "custom_dataloader = torch.utils.data.DataLoader(custom_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "rDcj-ZN-Xz_P"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "def get_score(model, device, train_loader, test_loader):\n",
    "    train_feature_space = []\n",
    "    with torch.no_grad():\n",
    "        for (imgs, _) in tqdm(train_loader, desc='Train set feature extracting'):\n",
    "            imgs = imgs.to(device)\n",
    "            features = model(imgs)\n",
    "            train_feature_space.append(features)\n",
    "        train_feature_space = torch.cat(train_feature_space, dim=0).contiguous().cpu().numpy()\n",
    "    test_feature_space = []\n",
    "    test_labels = []\n",
    "    with torch.no_grad():\n",
    "        for (imgs, labels) in tqdm(test_loader, desc='Test set feature extracting'):\n",
    "            imgs = imgs.to(device)\n",
    "            features = model(imgs)\n",
    "            test_feature_space.append(features)\n",
    "            test_labels.append(labels)\n",
    "        test_feature_space = torch.cat(test_feature_space, dim=0).contiguous().cpu().numpy()\n",
    "        test_labels = torch.cat(test_labels, dim=0).cpu().numpy()\n",
    "\n",
    "    distances = utils.knn_score(train_feature_space, test_feature_space)\n",
    "\n",
    "    auc = roc_auc_score(test_labels, distances)\n",
    "\n",
    "    return auc, train_feature_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "j4Fv8UaGX1if"
   },
   "outputs": [],
   "source": [
    "def get_loaders(dataset, label_class, batch_size, backbone):\n",
    "    if dataset == \"cifar100\":\n",
    "        ds = custom_dataloader\n",
    "        transform = transform_color if backbone == 152 else transform_resnet18\n",
    "        coarse = {}\n",
    "        trainset = ds(root='data', train=True, download=True, transform=transform, **coarse)\n",
    "        testset = ds(root='data', train=False, download=True, transform=transform, **coarse)\n",
    "        trainset_1 = ds(root='data', train=True, download=True, transform=Transform(), **coarse)\n",
    "        idx = np.array(trainset.targets) == label_class\n",
    "        testset.targets = [int(t != label_class) for t in testset.targets]\n",
    "        trainset.data = trainset.data[idx]\n",
    "        trainset.targets = [trainset.targets[i] for i, flag in enumerate(idx, 0) if flag]\n",
    "        trainset_1.data = trainset_1.data[idx]\n",
    "        trainset_1.targets = [trainset_1.targets[i] for i, flag in enumerate(idx, 0) if flag]\n",
    "        train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2,\n",
    "                                                   drop_last=False)\n",
    "        test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2,\n",
    "                                                  drop_last=False)\n",
    "        return train_loader, test_loader, torch.utils.data.DataLoader(trainset_1, batch_size=batch_size,\n",
    "                                                                      shuffle=True, num_workers=2, drop_last=False)\n",
    "    else:\n",
    "        print('Unsupported Dataset')\n",
    "        exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cb-FwsclX3KF",
    "outputId": "9c3f6e78-f1cb-4a05-c826-de5009085670"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0:\n",
      "Dataset: cifar100, Normal Label: 0, LR: 1e-05\n",
      "cuda:0\n",
      "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Train set feature extracting: 100% 8/8 [00:01<00:00,  4.12it/s]\n",
      "Test set feature extracting: 100% 157/157 [00:20<00:00,  7.62it/s]\n",
      "Epoch: 0, AUROC is: 0.9937919191919192\n",
      "Train...: 100% 8/8 [00:07<00:00,  1.03it/s]\n",
      "Epoch: 1, Loss: 3.9270719966888428\n",
      "Train set feature extracting: 100% 8/8 [00:01<00:00,  7.09it/s]\n",
      "Test set feature extracting: 100% 157/157 [00:18<00:00,  8.51it/s]\n",
      "Epoch: 1, AUROC is: 0.9938474747474748\n",
      "Train...: 100% 8/8 [00:08<00:00,  1.10s/it]\n",
      "Epoch: 2, Loss: 3.927179271697998\n",
      "Train set feature extracting: 100% 8/8 [00:01<00:00,  7.91it/s]\n",
      "Test set feature extracting: 100% 157/157 [00:18<00:00,  8.46it/s]\n",
      "Epoch: 2, AUROC is: 0.9938909090909092\n",
      "Train...: 100% 8/8 [00:08<00:00,  1.00s/it]\n",
      "Epoch: 3, Loss: 3.8687634468078613\n",
      "Train set feature extracting: 100% 8/8 [00:01<00:00,  7.54it/s]\n",
      "Test set feature extracting: 100% 157/157 [00:19<00:00,  8.02it/s]\n",
      "Epoch: 3, AUROC is: 0.9939434343434344\n",
      "Train...: 100% 8/8 [00:07<00:00,  1.05it/s]\n",
      "Epoch: 4, Loss: 3.8383130683898927\n",
      "Train set feature extracting: 100% 8/8 [00:01<00:00,  7.50it/s]\n",
      "Test set feature extracting: 100% 157/157 [00:19<00:00,  7.88it/s]\n",
      "Epoch: 4, AUROC is: 0.9939929292929293\n",
      "Train...: 100% 8/8 [00:06<00:00,  1.16it/s]\n",
      "Epoch: 5, Loss: 3.832082782745361\n",
      "Train set feature extracting: 100% 8/8 [00:01<00:00,  7.47it/s]\n",
      "Test set feature extracting: 100% 157/157 [00:21<00:00,  7.44it/s]\n",
      "Epoch: 5, AUROC is: 0.9940404040404041\n",
      "Train...: 100% 8/8 [00:07<00:00,  1.06it/s]\n",
      "Epoch: 6, Loss: 3.8543974533081053\n",
      "Train set feature extracting: 100% 8/8 [00:01<00:00,  6.38it/s]\n",
      "Test set feature extracting: 100% 157/157 [00:18<00:00,  8.41it/s]\n",
      "Epoch: 6, AUROC is: 0.9940979797979799\n",
      "Train...: 100% 8/8 [00:08<00:00,  1.04s/it]\n",
      "Epoch: 7, Loss: 3.812393014907837\n",
      "Train set feature extracting: 100% 8/8 [00:01<00:00,  7.51it/s]\n",
      "Test set feature extracting: 100% 157/157 [00:18<00:00,  8.44it/s]\n",
      "Epoch: 7, AUROC is: 0.9941353535353535\n",
      "Train...: 100% 8/8 [00:08<00:00,  1.01s/it]\n",
      "Epoch: 8, Loss: 3.8258057289123535\n",
      "Train set feature extracting: 100% 8/8 [00:01<00:00,  7.91it/s]\n",
      "Test set feature extracting: 100% 157/157 [00:18<00:00,  8.42it/s]\n",
      "Epoch: 8, AUROC is: 0.9941888888888889\n",
      "Train...: 100% 8/8 [00:07<00:00,  1.01it/s]\n",
      "Epoch: 9, Loss: 3.8260557193756104\n",
      "Train set feature extracting: 100% 8/8 [00:01<00:00,  7.63it/s]\n",
      "Test set feature extracting: 100% 157/157 [00:19<00:00,  8.20it/s]\n",
      "Epoch: 9, AUROC is: 0.994240404040404\n",
      "Train...: 100% 8/8 [00:07<00:00,  1.09it/s]\n",
      "Epoch: 10, Loss: 3.8036286029815676\n",
      "Train set feature extracting: 100% 8/8 [00:00<00:00,  8.06it/s]\n",
      "Test set feature extracting: 100% 157/157 [00:19<00:00,  7.93it/s]\n",
      "Epoch: 10, AUROC is: 0.9943020202020202\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting git+https://github.com/fra31/auto-attack\n",
      "  Cloning https://github.com/fra31/auto-attack to /tmp/pip-req-build-bkqauk52\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/fra31/auto-attack /tmp/pip-req-build-bkqauk52\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "for i in range(0, 100):\n",
    "    print(f\"Class {i}:\")\n",
    "    !python main.py --dataset=cifar100 --label={i} --backbone=18 --epochs=10\n",
    "    l = [x for (x, y) in class_loaders[i]]\n",
    "    x_test = torch.cat(l, 0)\n",
    "    l = [y for (x, y) in class_loaders[i]]\n",
    "    y_test = torch.cat(l, 0)\n",
    "    !pip install git+https://github.com/fra31/auto-attack\n",
    "    from autoattack import AutoAttack\n",
    "    adversary_Linf = AutoAttack(net, norm='Linf', eps=0.031, version='standard')\n",
    "    adv_complete_Linf = adversary_Linf.run_standard_evaluation(x_test, y_test,bs=64)   \n",
    "    adv_dataset_Linf = AdversarialDataset(adv_complete_Linf, y_test)\n",
    "    adv_loader_Linf = torch.utils.data.DataLoader(adv_dataset_Linf, batch_size=100, shuffle=False, num_workers=2)\n",
    "    import torch\n",
    "    import numpy as np\n",
    "\n",
    "    class CustomDataset(torch.utils.data.Dataset):\n",
    "        def __init__(self, images, labels):\n",
    "            self.images = images\n",
    "            self.labels = labels\n",
    "    \n",
    "        def __len__(self):\n",
    "            return len(self.images)\n",
    "    \n",
    "        def __getitem__(self, index):\n",
    "            image = self.images[index]\n",
    "            label = self.labels[index]\n",
    "            return torch.from_numpy(image), torch.tensor(label)\n",
    "\n",
    "    # Load datasets\n",
    "    dataset1 = x_test\n",
    "    dataset2 = adv_complete_Linf\n",
    "\n",
    "    # Create labels\n",
    "    labels1 = np.ones(dataset1.shape[0])\n",
    "    labels2 = np.zeros(dataset2.shape[0])\n",
    "\n",
    "    # Concatenate datasets\n",
    "    concatenated_dataset = np.concatenate((dataset1, dataset2), axis=0)\n",
    "    concatenated_labels = np.concatenate((labels1, labels2), axis=0)\n",
    "\n",
    "    # Shuffle dataset\n",
    "    permutation = np.random.permutation(concatenated_dataset.shape[0])\n",
    "    concatenated_dataset = concatenated_dataset[permutation]\n",
    "    concatenated_labels = concatenated_labels[permutation]\n",
    "\n",
    "    # Create dataset and dataloader\n",
    "    custom_dataset = CustomDataset(concatenated_dataset, concatenated_labels)\n",
    "    batch_size = 32\n",
    "    num_workers = 4\n",
    "    custom_dataloader = torch.utils.data.DataLoader(custom_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    import utils\n",
    "    model = utils.Model(backbone=18)\n",
    "    model = model.to(device)\n",
    "    train_loader, test_loader, train_loader_1 = utils.get_loaders(dataset=\"cifar100\", label_class=i, batch_size=1000, backbone=18)\n",
    "    a= get_score(model, device, train_loader, test_loader)\n",
    "    print(\"the AUROC for class\", i,'=', a[0])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
