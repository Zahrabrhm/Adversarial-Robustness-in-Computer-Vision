{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5bJB-CIYD3xE"
   },
   "source": [
    "Before starting we need to import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MjoLUW9aCofP"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import argparse\n",
    "import sys\n",
    "sys.argv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YAvCsdRbCdJQ"
   },
   "source": [
    "To ensure we get reproducible results we set the random seed for Python, Numpy and PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BN4WxssWDLJN"
   },
   "outputs": [],
   "source": [
    "SEED=1234\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic=True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ixNWzH5FJFcS"
   },
   "source": [
    "*  Defining Specific Resnet-18 structure introduces in TRADES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MbIGcZJ9Jxw7"
   },
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion * planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion * planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion * planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion * planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion * planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion * planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=100):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "def test():\n",
    "    net = ResNet18()\n",
    "    y = net(torch.randn(1, 3, 32, 32))\n",
    "    print(y.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iy14rTq6JzDd"
   },
   "source": [
    "*  Defining the loss function from TRADES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vU8Nvk7QKR6V"
   },
   "outputs": [],
   "source": [
    "def trades_loss(model,\n",
    "                x_natural,\n",
    "                y,\n",
    "                optimizer,\n",
    "                step_size=0.003,\n",
    "                epsilon=0.031,\n",
    "                perturb_steps=10,\n",
    "                beta=1.0,\n",
    "                distance='l_inf'):\n",
    "    # define KL-loss\n",
    "    criterion_kl = nn.KLDivLoss(size_average=False)\n",
    "    model.eval()\n",
    "    batch_size = len(x_natural)\n",
    "    # generate adversarial example\n",
    "    x_adv = x_natural.detach() + 0.001 * torch.randn(x_natural.shape).cuda().detach()\n",
    "    if distance == 'l_inf':\n",
    "        for _ in range(perturb_steps):\n",
    "            x_adv.requires_grad_()\n",
    "            with torch.enable_grad():\n",
    "                loss_kl = criterion_kl(F.log_softmax(model(x_adv), dim=1),\n",
    "                                       F.softmax(model(x_natural), dim=1))\n",
    "            grad = torch.autograd.grad(loss_kl, [x_adv])[0]\n",
    "            x_adv = x_adv.detach() + step_size * torch.sign(grad.detach())\n",
    "            x_adv = torch.min(torch.max(x_adv, x_natural - epsilon), x_natural + epsilon)\n",
    "            x_adv = torch.clamp(x_adv, 0.0, 1.0)\n",
    "    elif distance == 'l_2':\n",
    "        delta = 0.001 * torch.randn(x_natural.shape).cuda().detach()\n",
    "        delta = Variable(delta.data, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6z86EycVK_12"
   },
   "source": [
    "argument parser:\n",
    "This code sets up an argument parser using the argparse module, which allows you to define and parse command-line arguments. The arguments specify various hyperparameters and settings for training a neural network on the CIFAR100 dataset.\n",
    "\n",
    "Here's a brief summary of the arguments and their default values:\n",
    "\n",
    "--batch-size: Input batch size for training (default: 128)\n",
    "\n",
    "--test-batch-size: Input batch size for testing (default: 128)\n",
    "\n",
    "--epochs: Number of epochs to train (default: 76)\n",
    "\n",
    "--weight-decay or --wd: Weight decay (default: 2e-4)\n",
    "\n",
    "--lr: Learning rate (default: 0.1)\n",
    "\n",
    "--momentum or -m: SGD momentum (default: 0.9)\n",
    "\n",
    "--no-cuda: Disables CUDA training (default: False)\n",
    "\n",
    "--epsilon: Perturbation (default: 0.031)\n",
    "\n",
    "--num-steps: Perturb number of steps (default: 10)\n",
    "\n",
    "--step-size: Perturb step size (default: 0.007)\n",
    "\n",
    "--beta: Regularization, i.e., 1/lambda in TRADES (default: 6.0)\n",
    "\n",
    "--seed: Random seed (default: 1)\n",
    "\n",
    "--log-interval: How many batches to wait before logging training status (default: 100)\n",
    "\n",
    "--model-dir: Directory of model for saving checkpoint (default: './model-cifar-wideResNet')\n",
    "\n",
    "--save-freq or -s: Save frequency (default: 1)\n",
    "\n",
    "After defining these arguments, the code uses parser.parse_known_args() to parse any known arguments from the command line, and returns a Namespace object containing the parsed arguments as attributes.\n",
    "\n",
    "You can use these parsed arguments later in your code to set up the training loop, define the model architecture, or other relevant parts of the script. For example, you can access the learning rate using args.lr, the number of epochs using args.epochs, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-pPBrBbDMdkn"
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='PyTorch CIFAR 10 Training')\n",
    "parser.add_argument('--batch-size', type=int, default=128, metavar='N',\n",
    "                    help='input batch size for training (default: 128)')\n",
    "parser.add_argument('--test-batch-size', type=int, default=128, metavar='N',\n",
    "                    help='input batch size for testing (default: 128)')\n",
    "parser.add_argument('--epochs', type=int, default=76, metavar='N',\n",
    "                    help='number of epochs to train')\n",
    "parser.add_argument('--weight-decay', '--wd', default=2e-4,\n",
    "                    type=float, metavar='W')\n",
    "parser.add_argument('--lr', type=float, default=0.1, metavar='LR',\n",
    "                    help='learning rate')\n",
    "parser.add_argument('--momentum', type=float, default=0.9, metavar='M',\n",
    "                    help='SGD momentum')\n",
    "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                    help='disables CUDA training')\n",
    "parser.add_argument('--epsilon', default=0.031,\n",
    "                    help='perturbation')\n",
    "parser.add_argument('--num-steps', default=10,\n",
    "                    help='perturb number of steps')\n",
    "parser.add_argument('--step-size', default=0.007,\n",
    "                    help='perturb step size')\n",
    "parser.add_argument('--beta', default=6.0,\n",
    "                    help='regularization, i.e., 1/lambda in TRADES')\n",
    "parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                    help='random seed (default: 1)')\n",
    "parser.add_argument('--log-interval', type=int, default=100, metavar='N',\n",
    "                    help='how many batches to wait before logging training status')\n",
    "parser.add_argument('--model-dir', default='./model-cifar-wideResNet',\n",
    "                    help='directory of model for saving checkpoint')\n",
    "parser.add_argument('--save-freq', '-s', default=1, type=int, metavar='N',\n",
    "                    help='save frequency')\n",
    "\n",
    "args, unknown = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cOu_e-brMreI"
   },
   "source": [
    "*  sets some settings for a PyTorch model and prepares the device to be used for training or inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7C5VmIsgMxAh"
   },
   "outputs": [],
   "source": [
    "# settings\n",
    "model_dir = args.model_dir\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "torch.manual_seed(args.seed)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9wH-JKbcMziE"
   },
   "source": [
    "*  Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cSzjDHIQM7iJ",
    "outputId": "441cdb28-2a05-4d32-d3ac-7bd9ab583554"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:02<00:00, 61968846.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# setup data loader\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LrHYReqyM94X"
   },
   "source": [
    "*  Defining the natural training function to train model on normal Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sixHwnv1NIFr"
   },
   "outputs": [],
   "source": [
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = F.cross_entropy(model(data), target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print progress\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                       100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XrPhQONvNKA8"
   },
   "source": [
    "*  Defining evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P-RSxLamNQhk"
   },
   "outputs": [],
   "source": [
    "def eval_train(model, device, train_loader):\n",
    "    model.eval()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in train_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            train_loss += F.cross_entropy(output, target, size_average=False).item()\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    print('Training: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "        train_loss, correct, len(train_loader.dataset),\n",
    "        100. * correct / len(train_loader.dataset)))\n",
    "    training_accuracy = correct / len(train_loader.dataset)\n",
    "    return train_loss, training_accuracy\n",
    "\n",
    "\n",
    "def eval_test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output, target, size_average=False).item()\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('Test: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    test_accuracy = correct / len(test_loader.dataset)\n",
    "    return test_loss, test_accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JjVZFs1zNV3Q"
   },
   "source": [
    "*  Adjusting the Learning rate to decrease overtime for better convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8vRgOc2BNdbL"
   },
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"decrease the learning rate\"\"\"\n",
    "    lr = args.lr\n",
    "    if epoch >= 75:\n",
    "        lr = args.lr * 0.1\n",
    "    if epoch >= 90:\n",
    "        lr = args.lr * 0.01\n",
    "    if epoch >= 100:\n",
    "        lr = args.lr * 0.001\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SuMZ_LF_Njud"
   },
   "source": [
    "*  Training the model and evaluating on Cifar-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5gqjeHye4Zwt",
    "outputId": "8924c242-1d2a-411f-d585-33bc3de68277"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 4.656841\n",
      "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 1.982299\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 1.900848\n",
      "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 1.708506\n",
      "================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Average loss: 1.7604, Accuracy: 17462/50000 (35%)\n",
      "Test: Average loss: 1.7243, Accuracy: 3653/10000 (37%)\n",
      "================================================================\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 1.724769\n",
      "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 1.509554\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 1.623980\n",
      "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 1.391391\n",
      "================================================================\n",
      "Training: Average loss: 1.4503, Accuracy: 23887/50000 (48%)\n",
      "Test: Average loss: 1.4503, Accuracy: 4793/10000 (48%)\n",
      "================================================================\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 1.258327\n",
      "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 1.353818\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 1.278995\n",
      "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 1.169802\n",
      "================================================================\n",
      "Training: Average loss: 1.4215, Accuracy: 25829/50000 (52%)\n",
      "Test: Average loss: 1.4808, Accuracy: 5092/10000 (51%)\n",
      "================================================================\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 1.038900\n",
      "Train Epoch: 4 [12800/50000 (26%)]\tLoss: 0.962155\n",
      "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 1.074929\n",
      "Train Epoch: 4 [38400/50000 (77%)]\tLoss: 0.887222\n",
      "================================================================\n",
      "Training: Average loss: 1.2024, Accuracy: 29568/50000 (59%)\n",
      "Test: Average loss: 1.3050, Accuracy: 5716/10000 (57%)\n",
      "================================================================\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 0.831328\n",
      "Train Epoch: 5 [12800/50000 (26%)]\tLoss: 0.828820\n",
      "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 0.875069\n",
      "Train Epoch: 5 [38400/50000 (77%)]\tLoss: 0.751155\n",
      "================================================================\n",
      "Training: Average loss: 0.7742, Accuracy: 36449/50000 (73%)\n",
      "Test: Average loss: 0.8035, Accuracy: 7237/10000 (72%)\n",
      "================================================================\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLoss: 0.901679\n",
      "Train Epoch: 6 [12800/50000 (26%)]\tLoss: 0.646641\n",
      "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 0.663491\n",
      "Train Epoch: 6 [38400/50000 (77%)]\tLoss: 0.799213\n",
      "================================================================\n",
      "Training: Average loss: 0.7247, Accuracy: 37408/50000 (75%)\n",
      "Test: Average loss: 0.7358, Accuracy: 7509/10000 (75%)\n",
      "================================================================\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLoss: 0.673352\n",
      "Train Epoch: 7 [12800/50000 (26%)]\tLoss: 0.659491\n",
      "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 0.723407\n",
      "Train Epoch: 7 [38400/50000 (77%)]\tLoss: 0.624675\n",
      "================================================================\n",
      "Training: Average loss: 0.7960, Accuracy: 36262/50000 (73%)\n",
      "Test: Average loss: 0.8702, Accuracy: 7108/10000 (71%)\n",
      "================================================================\n",
      "Train Epoch: 8 [0/50000 (0%)]\tLoss: 0.604614\n",
      "Train Epoch: 8 [12800/50000 (26%)]\tLoss: 0.512170\n",
      "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 0.426783\n",
      "Train Epoch: 8 [38400/50000 (77%)]\tLoss: 0.566207\n",
      "================================================================\n",
      "Training: Average loss: 0.5864, Accuracy: 39789/50000 (80%)\n",
      "Test: Average loss: 0.6372, Accuracy: 7844/10000 (78%)\n",
      "================================================================\n",
      "Train Epoch: 9 [0/50000 (0%)]\tLoss: 0.425753\n",
      "Train Epoch: 9 [12800/50000 (26%)]\tLoss: 0.579232\n",
      "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 0.545987\n",
      "Train Epoch: 9 [38400/50000 (77%)]\tLoss: 0.449216\n",
      "================================================================\n",
      "Training: Average loss: 0.6319, Accuracy: 39166/50000 (78%)\n",
      "Test: Average loss: 0.7330, Accuracy: 7503/10000 (75%)\n",
      "================================================================\n",
      "Train Epoch: 10 [0/50000 (0%)]\tLoss: 0.575361\n",
      "Train Epoch: 10 [12800/50000 (26%)]\tLoss: 0.444395\n",
      "Train Epoch: 10 [25600/50000 (51%)]\tLoss: 0.466950\n",
      "Train Epoch: 10 [38400/50000 (77%)]\tLoss: 0.399706\n",
      "================================================================\n",
      "Training: Average loss: 0.4848, Accuracy: 41618/50000 (83%)\n",
      "Test: Average loss: 0.5365, Accuracy: 8164/10000 (82%)\n",
      "================================================================\n",
      "Train Epoch: 11 [0/50000 (0%)]\tLoss: 0.344075\n",
      "Train Epoch: 11 [12800/50000 (26%)]\tLoss: 0.396475\n",
      "Train Epoch: 11 [25600/50000 (51%)]\tLoss: 0.531114\n",
      "Train Epoch: 11 [38400/50000 (77%)]\tLoss: 0.338723\n",
      "================================================================\n",
      "Training: Average loss: 0.7291, Accuracy: 38192/50000 (76%)\n",
      "Test: Average loss: 0.8284, Accuracy: 7390/10000 (74%)\n",
      "================================================================\n",
      "Train Epoch: 12 [0/50000 (0%)]\tLoss: 0.310830\n",
      "Train Epoch: 12 [12800/50000 (26%)]\tLoss: 0.524754\n",
      "Train Epoch: 12 [25600/50000 (51%)]\tLoss: 0.397012\n",
      "Train Epoch: 12 [38400/50000 (77%)]\tLoss: 0.404823\n",
      "================================================================\n",
      "Training: Average loss: 0.5563, Accuracy: 40206/50000 (80%)\n",
      "Test: Average loss: 0.5930, Accuracy: 7983/10000 (80%)\n",
      "================================================================\n",
      "Train Epoch: 13 [0/50000 (0%)]\tLoss: 0.493913\n",
      "Train Epoch: 13 [12800/50000 (26%)]\tLoss: 0.323131\n",
      "Train Epoch: 13 [25600/50000 (51%)]\tLoss: 0.234594\n",
      "Train Epoch: 13 [38400/50000 (77%)]\tLoss: 0.377528\n",
      "================================================================\n",
      "Training: Average loss: 0.3987, Accuracy: 43026/50000 (86%)\n",
      "Test: Average loss: 0.5051, Accuracy: 8272/10000 (83%)\n",
      "================================================================\n",
      "Train Epoch: 14 [0/50000 (0%)]\tLoss: 0.404524\n",
      "Train Epoch: 14 [12800/50000 (26%)]\tLoss: 0.490814\n",
      "Train Epoch: 14 [25600/50000 (51%)]\tLoss: 0.370290\n",
      "Train Epoch: 14 [38400/50000 (77%)]\tLoss: 0.576601\n",
      "================================================================\n",
      "Training: Average loss: 0.4882, Accuracy: 41473/50000 (83%)\n",
      "Test: Average loss: 0.6049, Accuracy: 8042/10000 (80%)\n",
      "================================================================\n",
      "Train Epoch: 15 [0/50000 (0%)]\tLoss: 0.328856\n",
      "Train Epoch: 15 [12800/50000 (26%)]\tLoss: 0.228421\n",
      "Train Epoch: 15 [25600/50000 (51%)]\tLoss: 0.372510\n",
      "Train Epoch: 15 [38400/50000 (77%)]\tLoss: 0.487568\n",
      "================================================================\n",
      "Training: Average loss: 0.3604, Accuracy: 43838/50000 (88%)\n",
      "Test: Average loss: 0.4789, Accuracy: 8414/10000 (84%)\n",
      "================================================================\n",
      "Train Epoch: 16 [0/50000 (0%)]\tLoss: 0.285918\n",
      "Train Epoch: 16 [12800/50000 (26%)]\tLoss: 0.315964\n",
      "Train Epoch: 16 [25600/50000 (51%)]\tLoss: 0.475225\n",
      "Train Epoch: 16 [38400/50000 (77%)]\tLoss: 0.332398\n",
      "================================================================\n",
      "Training: Average loss: 0.3808, Accuracy: 43495/50000 (87%)\n",
      "Test: Average loss: 0.4860, Accuracy: 8399/10000 (84%)\n",
      "================================================================\n",
      "Train Epoch: 17 [0/50000 (0%)]\tLoss: 0.342320\n",
      "Train Epoch: 17 [12800/50000 (26%)]\tLoss: 0.343127\n",
      "Train Epoch: 17 [25600/50000 (51%)]\tLoss: 0.298646\n",
      "Train Epoch: 17 [38400/50000 (77%)]\tLoss: 0.390402\n",
      "================================================================\n",
      "Training: Average loss: 0.3607, Accuracy: 43756/50000 (88%)\n",
      "Test: Average loss: 0.4396, Accuracy: 8473/10000 (85%)\n",
      "================================================================\n",
      "Train Epoch: 18 [0/50000 (0%)]\tLoss: 0.181761\n",
      "Train Epoch: 18 [12800/50000 (26%)]\tLoss: 0.295729\n",
      "Train Epoch: 18 [25600/50000 (51%)]\tLoss: 0.281855\n",
      "Train Epoch: 18 [38400/50000 (77%)]\tLoss: 0.219931\n",
      "================================================================\n",
      "Training: Average loss: 0.3658, Accuracy: 43673/50000 (87%)\n",
      "Test: Average loss: 0.4621, Accuracy: 8435/10000 (84%)\n",
      "================================================================\n",
      "Train Epoch: 19 [0/50000 (0%)]\tLoss: 0.251845\n",
      "Train Epoch: 19 [12800/50000 (26%)]\tLoss: 0.257405\n",
      "Train Epoch: 19 [25600/50000 (51%)]\tLoss: 0.236524\n",
      "Train Epoch: 19 [38400/50000 (77%)]\tLoss: 0.262371\n",
      "================================================================\n",
      "Training: Average loss: 0.3926, Accuracy: 43343/50000 (87%)\n",
      "Test: Average loss: 0.5118, Accuracy: 8403/10000 (84%)\n",
      "================================================================\n",
      "Train Epoch: 20 [0/50000 (0%)]\tLoss: 0.238354\n",
      "Train Epoch: 20 [12800/50000 (26%)]\tLoss: 0.143525\n",
      "Train Epoch: 20 [25600/50000 (51%)]\tLoss: 0.289191\n",
      "Train Epoch: 20 [38400/50000 (77%)]\tLoss: 0.380592\n",
      "================================================================\n",
      "Training: Average loss: 0.4790, Accuracy: 42189/50000 (84%)\n",
      "Test: Average loss: 0.6009, Accuracy: 8166/10000 (82%)\n",
      "================================================================\n",
      "Train Epoch: 21 [0/50000 (0%)]\tLoss: 0.296289\n",
      "Train Epoch: 21 [12800/50000 (26%)]\tLoss: 0.251259\n",
      "Train Epoch: 21 [25600/50000 (51%)]\tLoss: 0.310612\n",
      "Train Epoch: 21 [38400/50000 (77%)]\tLoss: 0.219974\n",
      "================================================================\n",
      "Training: Average loss: 0.3387, Accuracy: 44085/50000 (88%)\n",
      "Test: Average loss: 0.4534, Accuracy: 8487/10000 (85%)\n",
      "================================================================\n",
      "Train Epoch: 22 [0/50000 (0%)]\tLoss: 0.268456\n",
      "Train Epoch: 22 [12800/50000 (26%)]\tLoss: 0.276580\n",
      "Train Epoch: 22 [25600/50000 (51%)]\tLoss: 0.219269\n",
      "Train Epoch: 22 [38400/50000 (77%)]\tLoss: 0.351574\n",
      "================================================================\n",
      "Training: Average loss: 0.3575, Accuracy: 43857/50000 (88%)\n",
      "Test: Average loss: 0.4690, Accuracy: 8514/10000 (85%)\n",
      "================================================================\n",
      "Train Epoch: 23 [0/50000 (0%)]\tLoss: 0.244214\n",
      "Train Epoch: 23 [12800/50000 (26%)]\tLoss: 0.219624\n",
      "Train Epoch: 23 [25600/50000 (51%)]\tLoss: 0.302162\n",
      "Train Epoch: 23 [38400/50000 (77%)]\tLoss: 0.272674\n",
      "================================================================\n",
      "Training: Average loss: 0.3082, Accuracy: 44592/50000 (89%)\n",
      "Test: Average loss: 0.4331, Accuracy: 8649/10000 (86%)\n",
      "================================================================\n",
      "Train Epoch: 24 [0/50000 (0%)]\tLoss: 0.212795\n",
      "Train Epoch: 24 [12800/50000 (26%)]\tLoss: 0.198844\n",
      "Train Epoch: 24 [25600/50000 (51%)]\tLoss: 0.279439\n",
      "Train Epoch: 24 [38400/50000 (77%)]\tLoss: 0.369689\n",
      "================================================================\n",
      "Training: Average loss: 0.3369, Accuracy: 44033/50000 (88%)\n",
      "Test: Average loss: 0.4532, Accuracy: 8540/10000 (85%)\n",
      "================================================================\n",
      "Train Epoch: 25 [0/50000 (0%)]\tLoss: 0.168444\n",
      "Train Epoch: 25 [12800/50000 (26%)]\tLoss: 0.300053\n",
      "Train Epoch: 25 [25600/50000 (51%)]\tLoss: 0.310204\n",
      "Train Epoch: 25 [38400/50000 (77%)]\tLoss: 0.255744\n",
      "================================================================\n",
      "Training: Average loss: 0.3088, Accuracy: 44655/50000 (89%)\n",
      "Test: Average loss: 0.4756, Accuracy: 8487/10000 (85%)\n",
      "================================================================\n",
      "Train Epoch: 26 [0/50000 (0%)]\tLoss: 0.309278\n",
      "Train Epoch: 26 [12800/50000 (26%)]\tLoss: 0.218169\n",
      "Train Epoch: 26 [25600/50000 (51%)]\tLoss: 0.136494\n",
      "Train Epoch: 26 [38400/50000 (77%)]\tLoss: 0.255555\n",
      "================================================================\n",
      "Training: Average loss: 0.3177, Accuracy: 44530/50000 (89%)\n",
      "Test: Average loss: 0.4362, Accuracy: 8553/10000 (86%)\n",
      "================================================================\n",
      "Train Epoch: 27 [0/50000 (0%)]\tLoss: 0.174264\n",
      "Train Epoch: 27 [12800/50000 (26%)]\tLoss: 0.150027\n",
      "Train Epoch: 27 [25600/50000 (51%)]\tLoss: 0.233795\n",
      "Train Epoch: 27 [38400/50000 (77%)]\tLoss: 0.262972\n",
      "================================================================\n",
      "Training: Average loss: 0.3637, Accuracy: 43790/50000 (88%)\n",
      "Test: Average loss: 0.5110, Accuracy: 8368/10000 (84%)\n",
      "================================================================\n",
      "Train Epoch: 28 [0/50000 (0%)]\tLoss: 0.298763\n",
      "Train Epoch: 28 [12800/50000 (26%)]\tLoss: 0.225406\n",
      "Train Epoch: 28 [25600/50000 (51%)]\tLoss: 0.205007\n",
      "Train Epoch: 28 [38400/50000 (77%)]\tLoss: 0.199948\n",
      "================================================================\n",
      "Training: Average loss: 0.3030, Accuracy: 44788/50000 (90%)\n",
      "Test: Average loss: 0.4436, Accuracy: 8629/10000 (86%)\n",
      "================================================================\n",
      "Train Epoch: 29 [0/50000 (0%)]\tLoss: 0.206435\n",
      "Train Epoch: 29 [12800/50000 (26%)]\tLoss: 0.301556\n",
      "Train Epoch: 29 [25600/50000 (51%)]\tLoss: 0.232033\n",
      "Train Epoch: 29 [38400/50000 (77%)]\tLoss: 0.188657\n",
      "================================================================\n",
      "Training: Average loss: 0.2679, Accuracy: 45323/50000 (91%)\n",
      "Test: Average loss: 0.3905, Accuracy: 8735/10000 (87%)\n",
      "================================================================\n",
      "Train Epoch: 30 [0/50000 (0%)]\tLoss: 0.138191\n",
      "Train Epoch: 30 [12800/50000 (26%)]\tLoss: 0.169370\n",
      "Train Epoch: 30 [25600/50000 (51%)]\tLoss: 0.164396\n",
      "Train Epoch: 30 [38400/50000 (77%)]\tLoss: 0.301654\n",
      "================================================================\n",
      "Training: Average loss: 0.3285, Accuracy: 44487/50000 (89%)\n",
      "Test: Average loss: 0.4728, Accuracy: 8489/10000 (85%)\n",
      "================================================================\n",
      "Train Epoch: 31 [0/50000 (0%)]\tLoss: 0.203503\n",
      "Train Epoch: 31 [12800/50000 (26%)]\tLoss: 0.205013\n",
      "Train Epoch: 31 [25600/50000 (51%)]\tLoss: 0.215536\n",
      "Train Epoch: 31 [38400/50000 (77%)]\tLoss: 0.252391\n",
      "================================================================\n",
      "Training: Average loss: 0.2635, Accuracy: 45487/50000 (91%)\n",
      "Test: Average loss: 0.4046, Accuracy: 8714/10000 (87%)\n",
      "================================================================\n",
      "Train Epoch: 32 [0/50000 (0%)]\tLoss: 0.336298\n",
      "Train Epoch: 32 [12800/50000 (26%)]\tLoss: 0.193852\n",
      "Train Epoch: 32 [25600/50000 (51%)]\tLoss: 0.206506\n",
      "Train Epoch: 32 [38400/50000 (77%)]\tLoss: 0.251645\n",
      "================================================================\n",
      "Training: Average loss: 0.2831, Accuracy: 45083/50000 (90%)\n",
      "Test: Average loss: 0.4203, Accuracy: 8650/10000 (86%)\n",
      "================================================================\n",
      "Train Epoch: 33 [0/50000 (0%)]\tLoss: 0.295719\n",
      "Train Epoch: 33 [12800/50000 (26%)]\tLoss: 0.282077\n",
      "Train Epoch: 33 [25600/50000 (51%)]\tLoss: 0.191377\n",
      "Train Epoch: 33 [38400/50000 (77%)]\tLoss: 0.333512\n",
      "================================================================\n",
      "Training: Average loss: 0.2906, Accuracy: 45047/50000 (90%)\n",
      "Test: Average loss: 0.4184, Accuracy: 8685/10000 (87%)\n",
      "================================================================\n",
      "Train Epoch: 34 [0/50000 (0%)]\tLoss: 0.246892\n",
      "Train Epoch: 34 [12800/50000 (26%)]\tLoss: 0.143294\n",
      "Train Epoch: 34 [25600/50000 (51%)]\tLoss: 0.135005\n",
      "Train Epoch: 34 [38400/50000 (77%)]\tLoss: 0.272329\n",
      "================================================================\n",
      "Training: Average loss: 0.3256, Accuracy: 44448/50000 (89%)\n",
      "Test: Average loss: 0.4478, Accuracy: 8588/10000 (86%)\n",
      "================================================================\n",
      "Train Epoch: 35 [0/50000 (0%)]\tLoss: 0.196151\n",
      "Train Epoch: 35 [12800/50000 (26%)]\tLoss: 0.231570\n",
      "Train Epoch: 35 [25600/50000 (51%)]\tLoss: 0.236033\n",
      "Train Epoch: 35 [38400/50000 (77%)]\tLoss: 0.254656\n",
      "================================================================\n",
      "Training: Average loss: 0.2623, Accuracy: 45401/50000 (91%)\n",
      "Test: Average loss: 0.4033, Accuracy: 8685/10000 (87%)\n",
      "================================================================\n",
      "Train Epoch: 36 [0/50000 (0%)]\tLoss: 0.137377\n",
      "Train Epoch: 36 [12800/50000 (26%)]\tLoss: 0.222547\n",
      "Train Epoch: 36 [25600/50000 (51%)]\tLoss: 0.210103\n",
      "Train Epoch: 36 [38400/50000 (77%)]\tLoss: 0.216030\n",
      "================================================================\n",
      "Training: Average loss: 0.2953, Accuracy: 44942/50000 (90%)\n",
      "Test: Average loss: 0.4609, Accuracy: 8561/10000 (86%)\n",
      "================================================================\n",
      "Train Epoch: 37 [0/50000 (0%)]\tLoss: 0.238445\n",
      "Train Epoch: 37 [12800/50000 (26%)]\tLoss: 0.170116\n",
      "Train Epoch: 37 [25600/50000 (51%)]\tLoss: 0.209525\n",
      "Train Epoch: 37 [38400/50000 (77%)]\tLoss: 0.246940\n",
      "================================================================\n",
      "Training: Average loss: 0.3126, Accuracy: 44587/50000 (89%)\n",
      "Test: Average loss: 0.4541, Accuracy: 8567/10000 (86%)\n",
      "================================================================\n",
      "Train Epoch: 38 [0/50000 (0%)]\tLoss: 0.148746\n",
      "Train Epoch: 38 [12800/50000 (26%)]\tLoss: 0.204233\n",
      "Train Epoch: 38 [25600/50000 (51%)]\tLoss: 0.269574\n",
      "Train Epoch: 38 [38400/50000 (77%)]\tLoss: 0.251088\n",
      "================================================================\n",
      "Training: Average loss: 0.3899, Accuracy: 43495/50000 (87%)\n",
      "Test: Average loss: 0.5100, Accuracy: 8427/10000 (84%)\n",
      "================================================================\n",
      "Train Epoch: 39 [0/50000 (0%)]\tLoss: 0.165370\n",
      "Train Epoch: 39 [12800/50000 (26%)]\tLoss: 0.119570\n",
      "Train Epoch: 39 [25600/50000 (51%)]\tLoss: 0.298154\n",
      "Train Epoch: 39 [38400/50000 (77%)]\tLoss: 0.328066\n",
      "================================================================\n",
      "Training: Average loss: 0.2826, Accuracy: 45166/50000 (90%)\n",
      "Test: Average loss: 0.4296, Accuracy: 8663/10000 (87%)\n",
      "================================================================\n",
      "Train Epoch: 40 [0/50000 (0%)]\tLoss: 0.208212\n",
      "Train Epoch: 40 [12800/50000 (26%)]\tLoss: 0.151317\n",
      "Train Epoch: 40 [25600/50000 (51%)]\tLoss: 0.151103\n",
      "Train Epoch: 40 [38400/50000 (77%)]\tLoss: 0.274591\n",
      "================================================================\n",
      "Training: Average loss: 0.2962, Accuracy: 44925/50000 (90%)\n",
      "Test: Average loss: 0.4695, Accuracy: 8558/10000 (86%)\n",
      "================================================================\n",
      "Train Epoch: 41 [0/50000 (0%)]\tLoss: 0.157647\n",
      "Train Epoch: 41 [12800/50000 (26%)]\tLoss: 0.302814\n",
      "Train Epoch: 41 [25600/50000 (51%)]\tLoss: 0.311984\n",
      "Train Epoch: 41 [38400/50000 (77%)]\tLoss: 0.289970\n",
      "================================================================\n",
      "Training: Average loss: 0.2523, Accuracy: 45618/50000 (91%)\n",
      "Test: Average loss: 0.3915, Accuracy: 8779/10000 (88%)\n",
      "================================================================\n",
      "Train Epoch: 42 [0/50000 (0%)]\tLoss: 0.201937\n",
      "Train Epoch: 42 [12800/50000 (26%)]\tLoss: 0.251175\n",
      "Train Epoch: 42 [25600/50000 (51%)]\tLoss: 0.284915\n",
      "Train Epoch: 42 [38400/50000 (77%)]\tLoss: 0.134033\n",
      "================================================================\n",
      "Training: Average loss: 0.2383, Accuracy: 45863/50000 (92%)\n",
      "Test: Average loss: 0.3697, Accuracy: 8800/10000 (88%)\n",
      "================================================================\n",
      "Train Epoch: 43 [0/50000 (0%)]\tLoss: 0.121439\n",
      "Train Epoch: 43 [12800/50000 (26%)]\tLoss: 0.179930\n",
      "Train Epoch: 43 [25600/50000 (51%)]\tLoss: 0.241229\n",
      "Train Epoch: 43 [38400/50000 (77%)]\tLoss: 0.387324\n",
      "================================================================\n",
      "Training: Average loss: 0.3123, Accuracy: 44743/50000 (89%)\n",
      "Test: Average loss: 0.4487, Accuracy: 8654/10000 (87%)\n",
      "================================================================\n",
      "Train Epoch: 44 [0/50000 (0%)]\tLoss: 0.188976\n",
      "Train Epoch: 44 [12800/50000 (26%)]\tLoss: 0.182051\n",
      "Train Epoch: 44 [25600/50000 (51%)]\tLoss: 0.201780\n",
      "Train Epoch: 44 [38400/50000 (77%)]\tLoss: 0.172833\n",
      "================================================================\n",
      "Training: Average loss: 0.1844, Accuracy: 46869/50000 (94%)\n",
      "Test: Average loss: 0.3092, Accuracy: 9009/10000 (90%)\n",
      "================================================================\n",
      "Train Epoch: 45 [0/50000 (0%)]\tLoss: 0.155315\n",
      "Train Epoch: 45 [12800/50000 (26%)]\tLoss: 0.183514\n",
      "Train Epoch: 45 [25600/50000 (51%)]\tLoss: 0.158674\n",
      "Train Epoch: 45 [38400/50000 (77%)]\tLoss: 0.265129\n",
      "================================================================\n",
      "Training: Average loss: 0.2907, Accuracy: 45092/50000 (90%)\n",
      "Test: Average loss: 0.4504, Accuracy: 8591/10000 (86%)\n",
      "================================================================\n",
      "Train Epoch: 46 [0/50000 (0%)]\tLoss: 0.151585\n",
      "Train Epoch: 46 [12800/50000 (26%)]\tLoss: 0.200241\n",
      "Train Epoch: 46 [25600/50000 (51%)]\tLoss: 0.160860\n",
      "Train Epoch: 46 [38400/50000 (77%)]\tLoss: 0.319372\n",
      "================================================================\n",
      "Training: Average loss: 0.1871, Accuracy: 46785/50000 (94%)\n",
      "Test: Average loss: 0.3389, Accuracy: 8905/10000 (89%)\n",
      "================================================================\n",
      "Train Epoch: 47 [0/50000 (0%)]\tLoss: 0.165322\n",
      "Train Epoch: 47 [12800/50000 (26%)]\tLoss: 0.180003\n",
      "Train Epoch: 47 [25600/50000 (51%)]\tLoss: 0.327371\n",
      "Train Epoch: 47 [38400/50000 (77%)]\tLoss: 0.144707\n",
      "================================================================\n",
      "Training: Average loss: 0.2512, Accuracy: 45666/50000 (91%)\n",
      "Test: Average loss: 0.4070, Accuracy: 8718/10000 (87%)\n",
      "================================================================\n",
      "Train Epoch: 48 [0/50000 (0%)]\tLoss: 0.155700\n",
      "Train Epoch: 48 [12800/50000 (26%)]\tLoss: 0.151172\n",
      "Train Epoch: 48 [25600/50000 (51%)]\tLoss: 0.250551\n",
      "Train Epoch: 48 [38400/50000 (77%)]\tLoss: 0.184580\n",
      "================================================================\n",
      "Training: Average loss: 0.2128, Accuracy: 46321/50000 (93%)\n",
      "Test: Average loss: 0.3642, Accuracy: 8833/10000 (88%)\n",
      "================================================================\n",
      "Train Epoch: 49 [0/50000 (0%)]\tLoss: 0.194253\n",
      "Train Epoch: 49 [12800/50000 (26%)]\tLoss: 0.230535\n",
      "Train Epoch: 49 [25600/50000 (51%)]\tLoss: 0.187766\n",
      "Train Epoch: 49 [38400/50000 (77%)]\tLoss: 0.219958\n",
      "================================================================\n",
      "Training: Average loss: 0.3166, Accuracy: 44592/50000 (89%)\n",
      "Test: Average loss: 0.4784, Accuracy: 8539/10000 (85%)\n",
      "================================================================\n",
      "Train Epoch: 50 [0/50000 (0%)]\tLoss: 0.283065\n",
      "Train Epoch: 50 [12800/50000 (26%)]\tLoss: 0.150408\n",
      "Train Epoch: 50 [25600/50000 (51%)]\tLoss: 0.282943\n",
      "Train Epoch: 50 [38400/50000 (77%)]\tLoss: 0.234949\n",
      "================================================================\n",
      "Training: Average loss: 0.2053, Accuracy: 46408/50000 (93%)\n",
      "Test: Average loss: 0.3419, Accuracy: 8869/10000 (89%)\n",
      "================================================================\n",
      "Train Epoch: 51 [0/50000 (0%)]\tLoss: 0.259816\n",
      "Train Epoch: 51 [12800/50000 (26%)]\tLoss: 0.115689\n",
      "Train Epoch: 51 [25600/50000 (51%)]\tLoss: 0.173984\n",
      "Train Epoch: 51 [38400/50000 (77%)]\tLoss: 0.205130\n",
      "================================================================\n",
      "Training: Average loss: 0.3104, Accuracy: 44742/50000 (89%)\n",
      "Test: Average loss: 0.4977, Accuracy: 8523/10000 (85%)\n",
      "================================================================\n",
      "Train Epoch: 52 [0/50000 (0%)]\tLoss: 0.166742\n",
      "Train Epoch: 52 [12800/50000 (26%)]\tLoss: 0.241154\n",
      "Train Epoch: 52 [25600/50000 (51%)]\tLoss: 0.170496\n",
      "Train Epoch: 52 [38400/50000 (77%)]\tLoss: 0.135247\n",
      "================================================================\n",
      "Training: Average loss: 0.2875, Accuracy: 45048/50000 (90%)\n",
      "Test: Average loss: 0.4539, Accuracy: 8627/10000 (86%)\n",
      "================================================================\n",
      "Train Epoch: 53 [0/50000 (0%)]\tLoss: 0.148776\n",
      "Train Epoch: 53 [12800/50000 (26%)]\tLoss: 0.256218\n",
      "Train Epoch: 53 [25600/50000 (51%)]\tLoss: 0.109075\n",
      "Train Epoch: 53 [38400/50000 (77%)]\tLoss: 0.204315\n",
      "================================================================\n",
      "Training: Average loss: 0.2046, Accuracy: 46454/50000 (93%)\n",
      "Test: Average loss: 0.3438, Accuracy: 8906/10000 (89%)\n",
      "================================================================\n",
      "Train Epoch: 54 [0/50000 (0%)]\tLoss: 0.123217\n",
      "Train Epoch: 54 [12800/50000 (26%)]\tLoss: 0.189896\n",
      "Train Epoch: 54 [25600/50000 (51%)]\tLoss: 0.231640\n",
      "Train Epoch: 54 [38400/50000 (77%)]\tLoss: 0.193478\n",
      "================================================================\n",
      "Training: Average loss: 0.2308, Accuracy: 45998/50000 (92%)\n",
      "Test: Average loss: 0.3917, Accuracy: 8749/10000 (87%)\n",
      "================================================================\n",
      "Train Epoch: 55 [0/50000 (0%)]\tLoss: 0.103204\n",
      "Train Epoch: 55 [12800/50000 (26%)]\tLoss: 0.101090\n",
      "Train Epoch: 55 [25600/50000 (51%)]\tLoss: 0.135285\n",
      "Train Epoch: 55 [38400/50000 (77%)]\tLoss: 0.225847\n",
      "================================================================\n",
      "Training: Average loss: 0.2348, Accuracy: 45930/50000 (92%)\n",
      "Test: Average loss: 0.3973, Accuracy: 8759/10000 (88%)\n",
      "================================================================\n",
      "Train Epoch: 56 [0/50000 (0%)]\tLoss: 0.148330\n",
      "Train Epoch: 56 [12800/50000 (26%)]\tLoss: 0.095037\n",
      "Train Epoch: 56 [25600/50000 (51%)]\tLoss: 0.223576\n",
      "Train Epoch: 56 [38400/50000 (77%)]\tLoss: 0.235471\n",
      "================================================================\n",
      "Training: Average loss: 0.2822, Accuracy: 45247/50000 (90%)\n",
      "Test: Average loss: 0.4439, Accuracy: 8669/10000 (87%)\n",
      "================================================================\n",
      "Train Epoch: 57 [0/50000 (0%)]\tLoss: 0.075462\n",
      "Train Epoch: 57 [12800/50000 (26%)]\tLoss: 0.141798\n",
      "Train Epoch: 57 [25600/50000 (51%)]\tLoss: 0.272400\n",
      "Train Epoch: 57 [38400/50000 (77%)]\tLoss: 0.232785\n",
      "================================================================\n",
      "Training: Average loss: 0.2842, Accuracy: 45224/50000 (90%)\n",
      "Test: Average loss: 0.4536, Accuracy: 8627/10000 (86%)\n",
      "================================================================\n",
      "Train Epoch: 58 [0/50000 (0%)]\tLoss: 0.113872\n",
      "Train Epoch: 58 [12800/50000 (26%)]\tLoss: 0.174047\n",
      "Train Epoch: 58 [25600/50000 (51%)]\tLoss: 0.199244\n",
      "Train Epoch: 58 [38400/50000 (77%)]\tLoss: 0.334979\n",
      "================================================================\n",
      "Training: Average loss: 0.1841, Accuracy: 46846/50000 (94%)\n",
      "Test: Average loss: 0.3471, Accuracy: 8913/10000 (89%)\n",
      "================================================================\n",
      "Train Epoch: 59 [0/50000 (0%)]\tLoss: 0.131677\n",
      "Train Epoch: 59 [12800/50000 (26%)]\tLoss: 0.313187\n",
      "Train Epoch: 59 [25600/50000 (51%)]\tLoss: 0.113443\n",
      "Train Epoch: 59 [38400/50000 (77%)]\tLoss: 0.193225\n",
      "================================================================\n",
      "Training: Average loss: 0.2792, Accuracy: 45299/50000 (91%)\n",
      "Test: Average loss: 0.4452, Accuracy: 8604/10000 (86%)\n",
      "================================================================\n",
      "Train Epoch: 60 [0/50000 (0%)]\tLoss: 0.183345\n",
      "Train Epoch: 60 [12800/50000 (26%)]\tLoss: 0.086774\n",
      "Train Epoch: 60 [25600/50000 (51%)]\tLoss: 0.252914\n",
      "Train Epoch: 60 [38400/50000 (77%)]\tLoss: 0.259452\n",
      "================================================================\n",
      "Training: Average loss: 0.2805, Accuracy: 45246/50000 (90%)\n",
      "Test: Average loss: 0.4498, Accuracy: 8650/10000 (86%)\n",
      "================================================================\n",
      "Train Epoch: 61 [0/50000 (0%)]\tLoss: 0.153795\n",
      "Train Epoch: 61 [12800/50000 (26%)]\tLoss: 0.120075\n",
      "Train Epoch: 61 [25600/50000 (51%)]\tLoss: 0.152221\n",
      "Train Epoch: 61 [38400/50000 (77%)]\tLoss: 0.177322\n",
      "================================================================\n",
      "Training: Average loss: 0.2508, Accuracy: 45821/50000 (92%)\n",
      "Test: Average loss: 0.4204, Accuracy: 8694/10000 (87%)\n",
      "================================================================\n",
      "Train Epoch: 62 [0/50000 (0%)]\tLoss: 0.134446\n",
      "Train Epoch: 62 [12800/50000 (26%)]\tLoss: 0.260306\n",
      "Train Epoch: 62 [25600/50000 (51%)]\tLoss: 0.221220\n",
      "Train Epoch: 62 [38400/50000 (77%)]\tLoss: 0.317357\n",
      "================================================================\n",
      "Training: Average loss: 0.2103, Accuracy: 46342/50000 (93%)\n",
      "Test: Average loss: 0.3690, Accuracy: 8846/10000 (88%)\n",
      "================================================================\n",
      "Train Epoch: 63 [0/50000 (0%)]\tLoss: 0.252858\n",
      "Train Epoch: 63 [12800/50000 (26%)]\tLoss: 0.106966\n",
      "Train Epoch: 63 [25600/50000 (51%)]\tLoss: 0.148863\n",
      "Train Epoch: 63 [38400/50000 (77%)]\tLoss: 0.148149\n",
      "================================================================\n",
      "Training: Average loss: 0.2106, Accuracy: 46276/50000 (93%)\n",
      "Test: Average loss: 0.3725, Accuracy: 8861/10000 (89%)\n",
      "================================================================\n",
      "Train Epoch: 64 [0/50000 (0%)]\tLoss: 0.094614\n",
      "Train Epoch: 64 [12800/50000 (26%)]\tLoss: 0.218111\n",
      "Train Epoch: 64 [25600/50000 (51%)]\tLoss: 0.176310\n",
      "Train Epoch: 64 [38400/50000 (77%)]\tLoss: 0.160172\n",
      "================================================================\n",
      "Training: Average loss: 0.2284, Accuracy: 46037/50000 (92%)\n",
      "Test: Average loss: 0.3977, Accuracy: 8744/10000 (87%)\n",
      "================================================================\n",
      "Train Epoch: 65 [0/50000 (0%)]\tLoss: 0.169941\n",
      "Train Epoch: 65 [12800/50000 (26%)]\tLoss: 0.098958\n",
      "Train Epoch: 65 [25600/50000 (51%)]\tLoss: 0.197415\n",
      "Train Epoch: 65 [38400/50000 (77%)]\tLoss: 0.230594\n",
      "================================================================\n",
      "Training: Average loss: 0.3993, Accuracy: 43464/50000 (87%)\n",
      "Test: Average loss: 0.5787, Accuracy: 8329/10000 (83%)\n",
      "================================================================\n",
      "Train Epoch: 66 [0/50000 (0%)]\tLoss: 0.205447\n",
      "Train Epoch: 66 [12800/50000 (26%)]\tLoss: 0.220349\n",
      "Train Epoch: 66 [25600/50000 (51%)]\tLoss: 0.119956\n",
      "Train Epoch: 66 [38400/50000 (77%)]\tLoss: 0.093945\n",
      "================================================================\n",
      "Training: Average loss: 0.1814, Accuracy: 46878/50000 (94%)\n",
      "Test: Average loss: 0.3546, Accuracy: 8948/10000 (89%)\n",
      "================================================================\n",
      "Train Epoch: 67 [0/50000 (0%)]\tLoss: 0.145973\n",
      "Train Epoch: 67 [12800/50000 (26%)]\tLoss: 0.214586\n",
      "Train Epoch: 67 [25600/50000 (51%)]\tLoss: 0.194725\n",
      "Train Epoch: 67 [38400/50000 (77%)]\tLoss: 0.195192\n",
      "================================================================\n",
      "Training: Average loss: 0.2806, Accuracy: 45331/50000 (91%)\n",
      "Test: Average loss: 0.4498, Accuracy: 8640/10000 (86%)\n",
      "================================================================\n",
      "Train Epoch: 68 [0/50000 (0%)]\tLoss: 0.064716\n",
      "Train Epoch: 68 [12800/50000 (26%)]\tLoss: 0.241431\n",
      "Train Epoch: 68 [25600/50000 (51%)]\tLoss: 0.228762\n",
      "Train Epoch: 68 [38400/50000 (77%)]\tLoss: 0.137851\n",
      "================================================================\n",
      "Training: Average loss: 0.2104, Accuracy: 46406/50000 (93%)\n",
      "Test: Average loss: 0.3778, Accuracy: 8823/10000 (88%)\n",
      "================================================================\n",
      "Train Epoch: 69 [0/50000 (0%)]\tLoss: 0.199129\n",
      "Train Epoch: 69 [12800/50000 (26%)]\tLoss: 0.109752\n",
      "Train Epoch: 69 [25600/50000 (51%)]\tLoss: 0.161136\n",
      "Train Epoch: 69 [38400/50000 (77%)]\tLoss: 0.172618\n",
      "================================================================\n",
      "Training: Average loss: 0.1679, Accuracy: 47105/50000 (94%)\n",
      "Test: Average loss: 0.3088, Accuracy: 8991/10000 (90%)\n",
      "================================================================\n",
      "Train Epoch: 70 [0/50000 (0%)]\tLoss: 0.160389\n",
      "Train Epoch: 70 [12800/50000 (26%)]\tLoss: 0.052470\n",
      "Train Epoch: 70 [25600/50000 (51%)]\tLoss: 0.100725\n",
      "Train Epoch: 70 [38400/50000 (77%)]\tLoss: 0.226263\n",
      "================================================================\n",
      "Training: Average loss: 0.2860, Accuracy: 45323/50000 (91%)\n",
      "Test: Average loss: 0.4517, Accuracy: 8673/10000 (87%)\n",
      "================================================================\n",
      "Train Epoch: 71 [0/50000 (0%)]\tLoss: 0.069018\n",
      "Train Epoch: 71 [12800/50000 (26%)]\tLoss: 0.194035\n",
      "Train Epoch: 71 [25600/50000 (51%)]\tLoss: 0.198103\n",
      "Train Epoch: 71 [38400/50000 (77%)]\tLoss: 0.150316\n",
      "================================================================\n",
      "Training: Average loss: 0.2598, Accuracy: 45646/50000 (91%)\n",
      "Test: Average loss: 0.4285, Accuracy: 8731/10000 (87%)\n",
      "================================================================\n",
      "Train Epoch: 72 [0/50000 (0%)]\tLoss: 0.136855\n",
      "Train Epoch: 72 [12800/50000 (26%)]\tLoss: 0.141536\n",
      "Train Epoch: 72 [25600/50000 (51%)]\tLoss: 0.267744\n",
      "Train Epoch: 72 [38400/50000 (77%)]\tLoss: 0.207639\n",
      "================================================================\n",
      "Training: Average loss: 0.1619, Accuracy: 47209/50000 (94%)\n",
      "Test: Average loss: 0.3118, Accuracy: 9036/10000 (90%)\n",
      "================================================================\n",
      "Train Epoch: 73 [0/50000 (0%)]\tLoss: 0.264625\n",
      "Train Epoch: 73 [12800/50000 (26%)]\tLoss: 0.158043\n",
      "Train Epoch: 73 [25600/50000 (51%)]\tLoss: 0.178634\n",
      "Train Epoch: 73 [38400/50000 (77%)]\tLoss: 0.209581\n",
      "================================================================\n",
      "Training: Average loss: 0.2077, Accuracy: 46429/50000 (93%)\n",
      "Test: Average loss: 0.3828, Accuracy: 8790/10000 (88%)\n",
      "================================================================\n",
      "Train Epoch: 74 [0/50000 (0%)]\tLoss: 0.201688\n",
      "Train Epoch: 74 [12800/50000 (26%)]\tLoss: 0.196076\n",
      "Train Epoch: 74 [25600/50000 (51%)]\tLoss: 0.145330\n",
      "Train Epoch: 74 [38400/50000 (77%)]\tLoss: 0.169270\n",
      "================================================================\n",
      "Training: Average loss: 0.2778, Accuracy: 45388/50000 (91%)\n",
      "Test: Average loss: 0.4573, Accuracy: 8654/10000 (87%)\n",
      "================================================================\n",
      "Train Epoch: 75 [0/50000 (0%)]\tLoss: 0.170079\n",
      "Train Epoch: 75 [12800/50000 (26%)]\tLoss: 0.069529\n",
      "Train Epoch: 75 [25600/50000 (51%)]\tLoss: 0.096569\n",
      "Train Epoch: 75 [38400/50000 (77%)]\tLoss: 0.035792\n",
      "================================================================\n",
      "Training: Average loss: 0.0437, Accuracy: 49361/50000 (99%)\n",
      "Test: Average loss: 0.2042, Accuracy: 9368/10000 (94%)\n",
      "================================================================\n",
      "Train Epoch: 76 [0/50000 (0%)]\tLoss: 0.040671\n",
      "Train Epoch: 76 [12800/50000 (26%)]\tLoss: 0.030138\n",
      "Train Epoch: 76 [25600/50000 (51%)]\tLoss: 0.069449\n",
      "Train Epoch: 76 [38400/50000 (77%)]\tLoss: 0.096682\n",
      "================================================================\n",
      "Training: Average loss: 0.0322, Accuracy: 49542/50000 (99%)\n",
      "Test: Average loss: 0.1925, Accuracy: 9388/10000 (94%)\n",
      "================================================================\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # init model, ResNet18() can be also used here for training\n",
    "    model = ResNet18().to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay)\n",
    "\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        # adjust learning rate for SGD\n",
    "        adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "        # adversarial training\n",
    "        train(args, model, device, train_loader, optimizer, epoch)\n",
    "\n",
    "        # evaluation on natural examples\n",
    "        print('================================================================')\n",
    "        eval_train(model, device, train_loader)\n",
    "        eval_test(model, device, test_loader)\n",
    "        print('================================================================')\n",
    "\n",
    "        # save checkpoint\n",
    "        if epoch % args.save_freq == 0:\n",
    "            torch.save(model.state_dict(),\n",
    "                       os.path.join(model_dir, 'model-resnet-epoch{}.pt'.format(epoch)))\n",
    "            torch.save(optimizer.state_dict(),\n",
    "                       os.path.join(model_dir, 'opt-resnet-checkpoint_epoch{}.tar'.format(epoch)))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
